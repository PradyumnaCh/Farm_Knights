{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunny/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import savez, save, load, array\n",
    "import os\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from numpy.random import seed, shuffle\n",
    "import h5py\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dataset(path):\n",
    "    dataset = []\n",
    "    num_categories = 38\n",
    "    labels = []\n",
    "    for i in range(38):\n",
    "        cat_path = path+'/c_'+str(i)\n",
    "        for img in os.listdir(cat_path):\n",
    "            temp = image.load_img(cat_path +'/'+img, target_size=(224,224,3))\n",
    "            temp = image.img_to_array(temp)\n",
    "            dataset.append(temp)\n",
    "            labels.append(i)\n",
    "        print('Category ' + str(i)+' out of 37 ', end='\\r')\n",
    "    print('Processing the input and saving. This may take some time in Vinay\\'s Lappy.')\n",
    "    dataset = array(dataset)\n",
    "    dataset = preprocess_input(dataset)\n",
    "    labels = array(labels).reshape(-1,1)\n",
    "    labels = to_categorical(labels, 38)\n",
    "    with h5py.File('crop_disease_dataset.h5', 'w') as h5:\n",
    "        h5.create_dataset('dataset', data=dataset)\n",
    "        h5.create_dataset('labels', data=labels)\n",
    "    print('Saved Dataset as .npz')\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the input and saving. This may take some time in Vinay's Lappy.\n",
      "Saved Dataset as .npz\n"
     ]
    }
   ],
   "source": [
    "train_path = '/Users/sunny/PycharmProjects/Keras/crowdai'\n",
    "train_dataset, train_labels = make_dataset(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('crop_disease_dataset.h5', 'r') as h5:\n",
    "    train_dataset = h5.get('dataset')[:]\n",
    "    train_labels = h5.get('labels')[:]\n",
    "#print(train_dataset, train_labels)\n",
    "train_dataset = array(train_dataset)\n",
    "train_labels = array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21917/21917 [==============================] - 7687s 351ms/step\n"
     ]
    }
   ],
   "source": [
    "#avoid this. this step is forward prop\n",
    "base_model = VGG16(weights = 'imagenet', include_top = False)\n",
    "train_features = base_model.predict(train_dataset, verbose=1)\n",
    "save('train_features', train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = train_features.reshape((21917,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#avoid forward prop by doing this\n",
    "train_features = load('train_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed(28)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "c = list(zip(train_features, train_labels))\n",
    "shuffle(c)\n",
    "train_features, train_labels = zip(*c)\n",
    "del c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = asarray(train_features)\n",
    "train_labels = asarray(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Flatten)\n",
    "model.add(Dense(1024, input_dim=7*7*512, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='sigmoid', kernel_initializer='glorot_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(38, activation='softmax', kernel_initializer='glorot_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers as op\n",
    "rm = op.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19725 samples, validate on 2192 samples\n",
      "Epoch 1/15\n",
      "19725/19725 [==============================] - 45s 2ms/step - loss: 2.2037 - acc: 0.4524 - val_loss: 0.9816 - val_acc: 0.7701\n",
      "Epoch 2/15\n",
      "19725/19725 [==============================] - 46s 2ms/step - loss: 1.1211 - acc: 0.7272 - val_loss: 0.5728 - val_acc: 0.8618\n",
      "Epoch 3/15\n",
      "19725/19725 [==============================] - 45s 2ms/step - loss: 0.7484 - acc: 0.8214 - val_loss: 0.4318 - val_acc: 0.8855\n",
      "Epoch 4/15\n",
      "19725/19725 [==============================] - 46s 2ms/step - loss: 0.5650 - acc: 0.8653 - val_loss: 0.3362 - val_acc: 0.8978\n",
      "Epoch 5/15\n",
      "19725/19725 [==============================] - 46s 2ms/step - loss: 0.4424 - acc: 0.8978 - val_loss: 0.2540 - val_acc: 0.9261\n",
      "Epoch 6/15\n",
      "19725/19725 [==============================] - 47s 2ms/step - loss: 0.3574 - acc: 0.9162 - val_loss: 0.2272 - val_acc: 0.9307\n",
      "Epoch 7/15\n",
      "19725/19725 [==============================] - 47s 2ms/step - loss: 0.3043 - acc: 0.9296 - val_loss: 0.2003 - val_acc: 0.9357\n",
      "Epoch 8/15\n",
      "19725/19725 [==============================] - 48s 2ms/step - loss: 0.2585 - acc: 0.9399 - val_loss: 0.1875 - val_acc: 0.9434\n",
      "Epoch 9/15\n",
      "19725/19725 [==============================] - 46s 2ms/step - loss: 0.2180 - acc: 0.9525 - val_loss: 0.1865 - val_acc: 0.9393\n",
      "Epoch 10/15\n",
      "19725/19725 [==============================] - 45s 2ms/step - loss: 0.1898 - acc: 0.9584 - val_loss: 0.1447 - val_acc: 0.9548\n",
      "Epoch 11/15\n",
      "19725/19725 [==============================] - 46s 2ms/step - loss: 0.1653 - acc: 0.9655 - val_loss: 0.1473 - val_acc: 0.9535\n",
      "Epoch 12/15\n",
      "19725/19725 [==============================] - 46s 2ms/step - loss: 0.1453 - acc: 0.9713 - val_loss: 0.1308 - val_acc: 0.9603\n",
      "Epoch 13/15\n",
      "19725/19725 [==============================] - 46s 2ms/step - loss: 0.1289 - acc: 0.9756 - val_loss: 0.1371 - val_acc: 0.9557\n",
      "Epoch 14/15\n",
      "19725/19725 [==============================] - 45s 2ms/step - loss: 0.1181 - acc: 0.9777 - val_loss: 0.1249 - val_acc: 0.9603\n",
      "Epoch 15/15\n",
      "19725/19725 [==============================] - 45s 2ms/step - loss: 0.1054 - acc: 0.9812 - val_loss: 0.1119 - val_acc: 0.9658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1896aecfd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model.fit(train_features, train_labels, batch_size = 128, epochs = 15, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('saved-weights_crop-disease.h5')\n",
    "model.save('saved_model_crop_diseases.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights = 'imagenet',include_top=False, input_shape=(224,224,3))\n",
    "dense_model = load_model('saved_model_crop_diseases.h5')\n",
    "base_model.outputs = [base_model.layers[-1].output]\n",
    "base_model.layers[-1].outbound_nodes = []\n",
    "bridge = base_model.layers[-1].output\n",
    "x = Flatten()(bridge)\n",
    "x = dense_model(x)\n",
    "final_model = Model(inputs = base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.save('complete_model_crop_diseases.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3594928e-05, 3.0621773e-05, 2.5025485e-05, 2.8380506e-05,\n",
       "        1.2420189e-04, 6.6766806e-06, 3.9539358e-04, 2.8080001e-05,\n",
       "        9.2108939e-06, 4.3103328e-06, 3.1790314e-06, 9.5520545e-06,\n",
       "        9.8290482e-05, 2.7662885e-05, 1.1313456e-04, 1.4238371e-05,\n",
       "        8.9367641e-06, 2.2999702e-05, 2.8416675e-06, 5.8443406e-06,\n",
       "        3.1657798e-06, 5.4985494e-06, 5.1723771e-05, 9.9989644e-05,\n",
       "        5.1113228e-05, 2.8239492e-05, 1.8301846e-05, 1.1667643e-04,\n",
       "        5.3115597e-05, 4.7838903e-04, 1.8603323e-05, 1.7368696e-03,\n",
       "        6.5252945e-02, 6.3563749e-02, 2.2298167e-03, 6.6739693e-04,\n",
       "        8.5840857e-01, 6.2437239e-03]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = image.load_img('feabce4c-9bb1-4fca-bcbf-368cacd40a68___PSU_CG 2115.JPG', target_size=(224,224,3))\n",
    "temp = image.img_to_array(temp)\n",
    "temp = preprocess_input(temp)\n",
    "temp = temp.reshape(1,224,224,3)\n",
    "final_model.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sunny/PycharmProjects/Keras'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
